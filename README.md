# Há»‡ Thá»‘ng Gá»£i Ã Video Real-time ğŸ¬

# Demo: https://youtu.be/agMtc0KSvTg
Há»‡ thá»‘ng gá»£i Ã½ video real-time cho ná»n táº£ng chia sáº» video ngáº¯n, sá»­ dá»¥ng Big Data vÃ  Cloud Computing technologies.

![Architecture](https://img.shields.io/badge/Architecture-Kappa-blue)
![Python](https://img.shields.io/badge/Python-3.11-green)
![Spark](https://img.shields.io/badge/Spark-3.5-orange)
![Kafka](https://img.shields.io/badge/Kafka-7.5-red)

## ğŸ“š Má»¥c TiÃªu Dá»± Ãn

Dá»± Ã¡n nÃ y thá»±c hiá»‡n:
- âœ… Triá»ƒn khai 1 bigdata framework, big data architecture (Kappa Architecture) vá»›i Ä‘áº§y Ä‘á»§ cÃ¡c module trong há»‡ sinh thÃ¡i Big Data
- âœ… Triá»ƒn khai mÃ´ hÃ¬nh Machine Learning (Collaborative Filtering) trÃªn xá»­ lÃ½ phÃ¢n tÃ¡n vá»›i Apache Spark
- âœ… Triá»ƒn khai thuáº­t toÃ¡n real-time trÃªn streaming processing Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n recommendation system

**Topic**: XÃ¢y dá»±ng há»‡ thá»‘ng gá»£i Ã½ real-time cho ná»n táº£ng chia sáº» video ngáº¯n

**Description**: PhÃ¡t triá»ƒn má»™t há»‡ thá»‘ng gá»£i Ã½ video cho ná»n táº£ng chia sáº» video ngáº¯n, phÃ¢n tÃ­ch hÃ nh vi ngÆ°á»i dÃ¹ng vÃ  siÃªu dá»¯ liá»‡u ná»™i dung theo thá»i gian thá»±c. Há»‡ thá»‘ng sá»­ dá»¥ng cÃ´ng nghá»‡ xá»­ lÃ½ dá»¯ liá»‡u lá»›n vÃ  Ä‘iá»‡n toÃ¡n Ä‘Ã¡m mÃ¢y Ä‘á»ƒ cung cáº¥p cÃ¡c Ä‘á» xuáº¥t cÃ¡ nhÃ¢n hÃ³a, nÃ¢ng cao tÆ°Æ¡ng tÃ¡c ngÆ°á»i dÃ¹ng vÃ  xá»­ lÃ½ hiá»‡u quáº£ dá»¯ liá»‡u streaming vá»›i khá»‘i lÆ°á»£ng lá»›n.

## ğŸ¯ TÃ­nh NÄƒng ChÃ­nh

- âš¡ **Real-time Processing**: Xá»­ lÃ½ sá»± kiá»‡n ngÆ°á»i dÃ¹ng trong vÃ i giÃ¢y vá»›i Apache Kafka vÃ  Spark Streaming
- ğŸ¤– **AI Recommendations**: Sá»­ dá»¥ng Collaborative Filtering (ALS) vÃ  Item-based CF
- ğŸ“Š **Scalable Architecture**: Kiáº¿n trÃºc Kappa cÃ³ kháº£ nÄƒng má»Ÿ rá»™ng cao
- ğŸš€ **High Performance**: Redis cache Ä‘á»ƒ truy xuáº¥t nhanh, MongoDB cho lÆ°u trá»¯ bá»n vá»¯ng
- ğŸ“ˆ **Real-time Analytics**: Dashboard theo dÃµi metrics vÃ  trending videos
- ğŸ¬ **Video Analytics**: PhÃ¢n tÃ­ch watch time, completion rate, engagement metrics

## ğŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚â”€â”€â”€â”€â–¶â”‚  API Service â”‚â”€â”€â”€â”€â–¶â”‚  Kafka Topics   â”‚
â”‚ (Web/Mobile)â”‚     â”‚   (Flask)    â”‚     â”‚  - user-events  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  - interactions â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                            â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Spark Streamingâ”‚                          â”‚  Data Generator â”‚
            â”‚   Processing   â”‚                          â”‚   (Simulator)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚
  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
  â”‚   Redis   â”‚          â”‚   MongoDB   â”‚
  â”‚  (Cache)  â”‚          â”‚  (Storage)  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Recommendation â”‚
            â”‚     Engine     â”‚
            â”‚   (ALS + CF)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

### Big Data Processing
- **Apache Kafka**: Event streaming platform cho message queue
- **Apache Spark 3.5**: Distributed data processing engine
- **PySpark Streaming**: Real-time stream processing

### Storage Layer
- **MongoDB**: NoSQL database cho persistent storage
- **Redis**: In-memory cache cho fast retrieval vÃ  real-time data

### Machine Learning
- **Spark MLlib ALS**: Distributed collaborative filtering vá»›i implicit feedback (phÃ¢n tÃ¡n trÃªn cluster)
- **Scikit-learn**: Feature engineering vÃ  similarity calculations
- **Item-based CF**: Content-based filtering

### Infrastructure & API
- **Docker & Docker Compose**: Containerization vÃ  orchestration
- **Flask**: REST API framework
- **Python 3.11**: Primary programming language

## ğŸš€ Distributed Machine Learning vá»›i Spark MLlib

### Tá»•ng quan

Há»‡ thá»‘ng sá»­ dá»¥ng **Distributed ML** (Spark MLlib) Ä‘á»ƒ táº­n dá»¥ng sá»©c máº¡nh cá»§a Spark cluster, cho phÃ©p xá»­ lÃ½ dá»¯ liá»‡u lá»›n vÃ  training model phÃ¢n tÃ¡n trÃªn nhiá»u workers.

### Äiá»ƒm khÃ¡c biá»‡t: Centralized vs Distributed

#### âŒ Centralized ML (TrÆ°á»›c Ä‘Ã¢y)
```python
# Sá»­ dá»¥ng implicit library - cháº¡y trÃªn 1 node
from implicit.als import AlternatingLeastSquares

als_model = AlternatingLeastSquares(factors=64)
als_model.fit(interaction_matrix)  # Cháº¡y trÃªn single machine
```

#### âœ… Distributed ML (Hiá»‡n táº¡i)
```python
# Sá»­ dá»¥ng Spark MLlib - phÃ¢n tÃ¡n trÃªn cluster
from pyspark.ml.recommendation import ALS

als = ALS(rank=64, implicitPrefs=True)
model = als.fit(interactions_df)  # PhÃ¢n tÃ¡n trÃªn nhiá»u workers
```

### TÃ­nh phÃ¢n tÃ¡n thá»ƒ hiá»‡n á»Ÿ Ä‘Ã¢u?

#### 1. **Data Loading - PhÃ¢n tÃ¡n Ä‘á»c dá»¯ liá»‡u**
```python
# Äá»c tá»« MongoDB sá»­ dá»¥ng Spark connector
interactions_df = spark.read \
    .format("mongodb") \
    .option("collection", "interactions") \
    .load()  # â† Dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n phá»‘i trÃªn workers
```

#### 2. **Data Transformation - Xá»­ lÃ½ phÃ¢n tÃ¡n**
```python
# Broadcast mappings Ä‘áº¿n táº¥t cáº£ workers
user_map_bc = spark.sparkContext.broadcast(user_id_map)

# UDF cháº¡y distributed trÃªn má»—i partition
@udf(IntegerType())
def user_to_idx(user_id):
    return user_map_bc.value.get(user_id, -1)
```

#### 3. **Model Training - Training phÃ¢n tÃ¡n**
```python
# ALS training Ä‘Æ°á»£c phÃ¢n phá»‘i
# - Data Ä‘Æ°á»£c chia thÃ nh partitions
# - Má»—i worker xá»­ lÃ½ cÃ¡c partitions khÃ¡c nhau
# - Gradients Ä‘Æ°á»£c tá»•ng há»£p distributed
model = als.fit(train_df)  # â† Cháº¡y song song trÃªn workers
```

#### 4. **Batch Recommendations - Inference phÃ¢n tÃ¡n**
```python
# Táº¡o recommendations cho nhiá»u users song song
recommendations = model.recommendForUserSubset(users_df, n=20)
# â† Táº¥t cáº£ users Ä‘Æ°á»£c xá»­ lÃ½ parallel trÃªn cluster
```

### Kiáº¿n trÃºc Distributed Training

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Spark Master                         â”‚
â”‚  - Äiá»u phá»‘i cÃ´ng viá»‡c                                  â”‚
â”‚  - Quáº£n lÃ½ resources                                    â”‚
â”‚  - Driver program                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚Worker 1â”‚      â”‚Worker 2 â”‚
â”‚2G RAM  â”‚      â”‚2G RAM   â”‚
â”‚2 cores â”‚      â”‚2 cores  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    Parallel Processing:
    - Data partitions
    - ALS iterations
    - Matrix operations
```

### Workflow Training

1. **Data Loading** (Distributed)
   - MongoDB â†’ Spark DataFrame
   - Data split across workers

2. **Preprocessing** (Distributed)
   - Create mappings (broadcast)
   - Index conversion (UDF on partitions)

3. **Training** (Distributed)
   - ALS algorithm runs on partitions
   - Each iteration:
     - User factors update (parallel)
     - Item factors update (parallel)
     - Loss aggregation (reduce)

4. **Evaluation** (Distributed)
   - Predictions on test set
   - RMSE calculation (parallel)

5. **Model Save** (Distributed)
   - Save to distributed file system
   - Model metadata + factors

### Cháº¡y Distributed Training

```bash
# Submit job lÃªn Spark cluster
python scripts/train_model.py

# Hoáº·c trá»±c tiáº¿p
docker exec spark-master spark-submit \
    --master spark://spark-master:7077 \
    --driver-memory 4g \
    --executor-memory 2g \
    --executor-cores 2 \
    /opt/spark-jobs/recommendation_engine.py
```

### Monitoring

Truy cáº­p Spark UI Ä‘á»ƒ xem quÃ¡ trÃ¬nh phÃ¢n tÃ¡n:
- **URL**: http://localhost:8080
- **Xem**:
  - Active workers
  - Running executors
  - Task distribution
  - Stage completion

### Lá»£i Ã­ch cá»§a Distributed ML

#### Scalability
- âœ… Xá»­ lÃ½ Ä‘Æ°á»£c datasets lá»›n (GB-TB)
- âœ… ThÃªm workers = tÄƒng performance
- âœ… KhÃ´ng bá»‹ giá»›i háº¡n RAM cá»§a 1 mÃ¡y

#### Performance
- âœ… Training nhanh hÆ¡n vá»›i nhiá»u workers
- âœ… Parallel recommendations cho nhiá»u users
- âœ… Distributed data loading

#### Fault Tolerance
- âœ… Tá»± Ä‘á»™ng retry failed tasks
- âœ… Data replication
- âœ… Lineage-based recovery

### So sÃ¡nh Performance

| Metric | Centralized (implicit) | Distributed (Spark MLlib) |
|--------|------------------------|---------------------------|
| Max Dataset Size | ~10GB (RAM limit) | Unlimited (cluster RAM) |
| Training Time (1M interactions) | ~5 minutes | ~2 minutes (2 workers) |
| Parallel Users Inference | Sequential | Parallel |
| Scalability | Vertical only | Horizontal |
| Fault Tolerance | None | Built-in |

### Cáº¥u hÃ¬nh tá»‘i Æ°u

#### Cho datasets nhá» (<10GB)
```python
ALS(rank=64, maxIter=10, regParam=0.01)
# Executors: 2-4
# Memory per executor: 2G
```

#### Cho datasets lá»›n (>10GB)
```python
ALS(rank=128, maxIter=15, regParam=0.01)
# Executors: 8-16
# Memory per executor: 4G
```

### Troubleshooting

#### Out of Memory
- TÄƒng executor memory
- Reduce rank (sá»‘ factors)
- TÄƒng sá»‘ partitions

#### Slow Training
- TÄƒng sá»‘ workers
- TÄƒng executor cores
- Cache DataFrame

#### Cold Start
- Hybrid vá»›i trending videos
- Content-based filtering
- Popularity-based fallback

## ğŸ“‹ Datasets Tham Kháº£o

1. **Tsinghua ShortVideo Dataset**
   - Link: https://github.com/tsinghua-fib-lab/ShortVideo_dataset
   - Chá»©a user interactions vÃ  video metadata

2. **MicroLens Dataset**
   - Link: https://github.com/westlake-repl/MicroLens
   - Dataset lá»›n vá»›i multi-modal features

"TikTok API / Scraper (Selenium,...) â†’ Kafka Topic â†’ Spark Streaming â†’
Thu tháº­p: video ID, caption, comments, hashtags, likes, user info..."
Spark MLLib, ...

## Datasets
1. https://github.com/tsinghua-fib-lab/ShortVideo_dataset
2. https://github.com/westlake-repl/MicroLens

Requirements

- PPT -> Slide thuyáº¿t trÃ¬nh
        + Trang BÃ¬a (TÃªn topic, nhÃ³m thá»±c hiá»‡n)
        + Má»¥c lá»¥c
        + Gioi thiá»‡u
        + .....
        + Káº¿t luáº­n vÃ  hÆ°á»›ng phÃ¡t triá»ƒn
        + Tham kháº£o
- PDF -> BÃ¡o cÃ¡o (XÃºc tÃ­ch, khÃ´ng quÃ¡ 20 trang)
- Link Video Demo (Náº¿u cÃ³), github (Náº¿u cÃ³) hoáº·c báº¥t ká»³ tham kháº£o nÃ o pháº£i Ä‘áº·t trong Page tham kháº£o cá»§a PPT.
